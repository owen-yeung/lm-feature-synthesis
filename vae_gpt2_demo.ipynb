{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9d11b09",
   "metadata": {},
   "source": [
    "Result\n",
    "\n",
    "The target direction is the hidden state for “D’Angelo is a former professional boxer, who has won five world titles, including the WBA Light Middleweight Title, the WBA Light Middleweight Title, the WBA Light Middleweight Title, the WBA Light Middleweight Title, and the WBA Light Middleweight Title.”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Misc\n",
    "Optimus class is here for fast iteration, maybe should use as seperate module later\n",
    "\n",
    "Maybe fix retain_graph if speed is a bottleneck\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe642d5e",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you're in the spar-red-tem/owen directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd ..\n",
    "# !pip install --upgrade transformers\n",
    "# !pip3 install torch torchvision\n",
    "\n",
    "# !pip install -r ~/GENIES/requirements.txt\n",
    "# !nvidia-smi\n",
    "# %ls\n",
    "# Load model directly\n",
    "\n",
    "# from transformers import AutoTokenizer\n",
    "# from transformers import GPT2OptimusForLatentConnector as GPT2OptimusForLatentConnector_hf\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"fusing/gpt2_optimus\")\n",
    "# model = GPT2OptimusForLatentConnector_hf.from_pretrained(\"fusing/gpt2_optimus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "856ff2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "# import pandas as pd\n",
    "\n",
    "# import numpy as np\n",
    "# import datasets\n",
    "# import accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cacdb7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A string from wikipedia about shaq\n",
    "shaq = \"Shaquille O'Neal is a 7-foot-1-inch (2.16 m) and 325-pound (147 kg) center who played for six teams over his 19-year career in the National Basketball Association (NBA) and is a four-time NBA champion. O'Neal is regarded as one of the greatest basketball players and centers of all time.\"\n",
    "# A string from wikipedia about benzene\n",
    "benzene = \"Benzene is a natural constituent of petroleum and is one of the elementary petrochemicals. Due to the cyclic continuous pi bonds between the carbon atoms, benzene is classed as an aromatic hydrocarbon. Benzene is a colorless and highly flammable liquid with a sweet smell, and is partially responsible for the aroma of gasoline.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimus (code copied here for iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Optimus_dir.code.Optimus import Optimus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Optimus_dir.code.Optimus import Optimus\n",
    "#Should check if optimus can encode-decode successfully\n",
    "#Adapted from run_latent_generation.py\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "# import argparse\n",
    "# import glob\n",
    "# import logging\n",
    "import os\n",
    "# import pickle\n",
    "# import random\n",
    "from typing import Tuple, Union, Any, Dict, List\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "# import gen_utils as utils # helper functions originally in run_latent_generation.py\n",
    "# from .Args import Args \n",
    "\n",
    "# from torch.utils.data import DataLoader, Dataset, SequentialSampler, RandomSampler, TensorDataset\n",
    "# from torch.utils.data.distributed import DistributedSampler\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "# PARENT = 'Optimus_dir.code'\n",
    "from Optimus_dir.code.pytorch_transformers import GPT2Config, OpenAIGPTConfig, XLNetConfig, TransfoXLConfig, BertConfig\n",
    "from Optimus_dir.code.pytorch_transformers import GPT2Tokenizer, GPT2ForLatentConnector #, GPT2LMHeadModel, \n",
    "# from .pytorch_transformers import OpenAIGPTLMHeadModel, OpenAIGPTTokenizer\n",
    "# from .pytorch_transformers import XLNetLMHeadModel, XLNetTokenizer\n",
    "# from .pytorch_transformers import TransfoXLLMHeadModel, TransfoXLTokenizer\n",
    "from Optimus_dir.code.pytorch_transformers import BertForLatentConnector, BertTokenizer\n",
    "\n",
    "from collections import defaultdict\n",
    "from Optimus_dir.code.examples.big_ae.modules import VAE \n",
    "# from .examples.big_ae.utils import (TextDataset_Split, TextDataset_2Tokenizers, BucketingDataLoader)\n",
    "\n",
    "# import pdb\n",
    "\n",
    "class Optimus:\n",
    "    MAX_LENGTH = int(10000)  # Hardcoded max length to avoid infinite loop\n",
    "\n",
    "    ALL_MODELS = sum((tuple(conf.pretrained_config_archive_map.keys()) for conf in (GPT2Config, OpenAIGPTConfig, XLNetConfig, TransfoXLConfig)), ())\n",
    "\n",
    "    MODEL_CLASSES = {\n",
    "        'gpt2': (GPT2Config, GPT2ForLatentConnector, GPT2Tokenizer),\n",
    "        'bert': (BertConfig, BertForLatentConnector, BertTokenizer)\n",
    "    }\n",
    "\n",
    "    # Padding text to help Transformer-XL and XLNet with short prompts as proposed by Aman Rusia\n",
    "    # in https://github.com/rusiaaman/XLNet-gen#methodology\n",
    "    # and https://medium.com/@amanrusia/xlnet-speaks-comparison-to-gpt-2-ea1a4e9ba39e\n",
    "    PADDING_TEXT = \"\"\" In 1991, the remains of Russian Tsar Nicholas II and his family\n",
    "    (except for Alexei and Maria) are discovered.\n",
    "    The voice of Nicholas's young son, Tsarevich Alexei Nikolaevich, narrates the\n",
    "    remainder of the story. 1883 Western Siberia,\n",
    "    a young Grigori Rasputin is asked by his father and a group of men to perform magic.\n",
    "    Rasputin has a vision and denounces one of the men as a horse thief. Although his\n",
    "    father initially slaps him for making such an accusation, Rasputin watches as the\n",
    "    man is chased outside and beaten. Twenty years later, Rasputin sees a vision of\n",
    "    the Virgin Mary, prompting him to become a priest. Rasputin quickly becomes famous,\n",
    "    with people, even a bishop, begging for his blessing. <eod> </s> <eos>\"\"\"\n",
    "\n",
    "    def __init__(self, latent_size=32, beta=0.5) -> None:\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            latent_size (int, optional): _description_. Defaults to 32.\n",
    "            beta (float, optional): _description_. Defaults to 0.5.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: _description_\n",
    "        \"\"\"        \n",
    "        # no model choice for now, fix architecture and checkpoint for simplicity?\n",
    "\n",
    "        directory = 'Optimus_dir/code/checkpoints' # edit if file structure changes\n",
    "        self.latent_size = latent_size\n",
    "        self.num_layers = 12 # correct for GPT-2\n",
    "        self.hidden_size = 768 # correct for GPT-2\n",
    "\n",
    "        train_data_file = f'{directory}/train.txt'\n",
    "        eval_data_file = f'{directory}/test.txt'\n",
    "        if latent_size == 768 and beta == 0.5:\n",
    "            checkpoint_dir = f'{directory}/optimus_latent768_beta05'\n",
    "            self.latent_size = 768\n",
    "        # elif latent_size == 768 and beta == 1.0:\n",
    "        #     checkpoint_dir = f'{directory}/optimus_latent768_beta1'\n",
    "        elif latent_size == 32:\n",
    "            checkpoint_dir = f'{directory}/optimus_latent32_beta05'\n",
    "            self.latent_size = 32\n",
    "        else:\n",
    "            raise ValueError('Only latent size 32 and 768 supported')\n",
    "        # checkpoint_dir = f'{directory}/optimus_latent32_beta05'\n",
    "        \n",
    "        output_dir = f'{directory}/outputs'\n",
    "        # train_data_file = None\n",
    "        # eval_data_file = None\n",
    "        # output_dir = None\n",
    "\n",
    "        args = Args(train_data_file, eval_data_file, checkpoint_dir, output_dir)\n",
    "        # args.device = torch.device(\"cuda\" if torch.cuda.is_available() and not args.no_cuda else \"cpu\")\n",
    "        self.device = args.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        args.n_gpu = torch.cuda.device_count()\n",
    "        args.latent_size = latent_size\n",
    "        # args.beta = beta\n",
    "\n",
    "        Optimus.set_seed(args)\n",
    "\n",
    "        global_step = args.gloabl_step_eval\n",
    "\n",
    "        output_encoder_dir = os.path.join(args.checkpoint_dir, 'checkpoint-encoder-{}'.format(global_step))\n",
    "        output_decoder_dir = os.path.join(args.checkpoint_dir, 'checkpoint-decoder-{}'.format(global_step)) \n",
    "        checkpoints = [ [output_encoder_dir, output_decoder_dir] ]\n",
    "\n",
    "        # Load a trained Encoder model and vocabulary that you have fine-tuned\n",
    "        encoder_config_class, encoder_model_class, encoder_tokenizer_class = Optimus.MODEL_CLASSES[args.encoder_model_type]\n",
    "        model_encoder = encoder_model_class.from_pretrained(output_encoder_dir, latent_size=args.latent_size)\n",
    "        tokenizer_encoder = encoder_tokenizer_class.from_pretrained(args.encoder_tokenizer_name if args.encoder_tokenizer_name else args.encoder_model_name_or_path, do_lower_case=args.do_lower_case)\n",
    "        self.tokenizer_encoder = tokenizer_encoder\n",
    "        \n",
    "        model_encoder.to(args.device)\n",
    "        if args.block_size <= 0:\n",
    "            args.block_size = tokenizer_encoder.max_len_single_sentence  # Our input block size will be the max possible for the model\n",
    "        args.block_size = min(args.block_size, tokenizer_encoder.max_len_single_sentence)\n",
    "        decoder_config_class, decoder_model_class, decoder_tokenizer_class = Optimus.MODEL_CLASSES[args.decoder_model_type]\n",
    "\n",
    "        model_decoder = decoder_model_class.from_pretrained(\n",
    "            output_decoder_dir, latent_size=args.latent_size,\n",
    "            output_hidden_states=True, # added, hopefully doesn't break rest of code lol\n",
    "            )\n",
    "        self.model_decoder_with_hidden = decoder_model_class.from_pretrained(output_decoder_dir, latent_size=args.latent_size, output_hidden_states=True)\n",
    "        #     tokenizer_decoder = decoder_tokenizer_class.from_pretrained(args.decoder_tokenizer_name if args.decoder_tokenizer_name else args.decoder_model_name_or_path, do_lower_case=args.do_lower_case)\n",
    "        # tokenizer_decoder = AutoTokenizer.from_pretrained(\"gpt2\", use_fast = False) # shitty fix for decoder tokenizer\n",
    "        tokenizer_decoder = GPT2Tokenizer.from_pretrained(\"gpt2\") # shitty fix for decoder tokenizer\n",
    "        self.tokenizer_decoder = tokenizer_decoder\n",
    "        model_decoder.to(args.device)\n",
    "        if args.block_size <= 0:\n",
    "            args.block_size = tokenizer_decoder.max_len_single_sentence  # Our input block size will be the max possible for the model\n",
    "        args.block_size = min(args.block_size, tokenizer_decoder.max_len_single_sentence)\n",
    "\n",
    "        # Load full model\n",
    "        output_full_dir    = os.path.join(args.checkpoint_dir, 'checkpoint-full-{}'.format(global_step)) \n",
    "        checkpoint = torch.load(os.path.join(output_full_dir, 'training.bin'), map_location=self.device)\n",
    "\n",
    "        # Chunyuan: Add Padding token to GPT2\n",
    "        special_tokens_dict = {'pad_token': '<PAD>', 'bos_token': '<BOS>', 'eos_token': '<EOS>'}\n",
    "        num_added_toks = tokenizer_decoder.add_special_tokens(special_tokens_dict)\n",
    "        print('We have added', num_added_toks, 'tokens to GPT2')\n",
    "        model_decoder.resize_token_embeddings(len(tokenizer_decoder))  # Notice: resize_token_embeddings expect to receive the full size of the new vocabulary, i.e. the length of the tokenizer.\n",
    "        assert tokenizer_decoder.pad_token == '<PAD>'\n",
    "\n",
    "        self.model_vae = VAE(model_encoder, model_decoder, tokenizer_encoder, tokenizer_decoder, args)\n",
    "        self.model_vae.load_state_dict(checkpoint['model_state_dict'])\n",
    "        self.model_vae.to(args.device)\n",
    "        # self.tokenizer_encoder = \n",
    "        self.args = args\n",
    "\n",
    "        bos_id = self.model_vae.tokenizer_decoder.encode('<BOS>')\n",
    "        bos_id = torch.tensor(bos_id, dtype=torch.long, device=self.device)\n",
    "        self.bos_id = bos_id.unsqueeze(0).repeat(1, 1)  \n",
    "\n",
    "    def set_seed(args):\n",
    "        np.random.seed(args.seed)\n",
    "        torch.manual_seed(args.seed)\n",
    "        if args.n_gpu > 0:\n",
    "            torch.cuda.manual_seed_all(args.seed)\n",
    "    \n",
    "    def latent_code_from_text(self, text: str,) -> Tuple[torch.Tensor, int]:\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            text (str): _description_\n",
    "\n",
    "        Returns:\n",
    "            Tuple[torch.Tensor, int]: _description_\n",
    "        \"\"\"        \n",
    "        tokenized1 = self.model_vae.tokenizer_encoder.encode(text)\n",
    "        tokenized1 = [101] + tokenized1 + [102] # Change this so same tokens in both methods\n",
    "        coded1 = torch.Tensor([tokenized1])\n",
    "        coded1 =torch.Tensor.long(coded1)\n",
    "        with torch.no_grad():\n",
    "            x0 = coded1\n",
    "            x0 = x0.to(self.args.device)\n",
    "            pooled_hidden_fea = self.model_vae.encoder(x0, attention_mask=(x0 > 0).float())[1]\n",
    "            mean, logvar = self.model_vae.encoder.linear(pooled_hidden_fea).chunk(2, -1)\n",
    "            latent_z = mean.squeeze(1)  \n",
    "            coded_length = len(tokenized1)\n",
    "            return latent_z, coded_length\n",
    "\n",
    "    # def logits_from_latent_code(self, latent_z,):\n",
    "    #     # Logits from which position? What did the paper do?\n",
    "    #     raise NotImplementedError\n",
    "\n",
    "    def print_n_texts_from_latent_code(self, latent_z: torch.Tensor, n=5, perturb=0.0) -> None:\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            latent_z (torch.Tensor): _description_\n",
    "            n (int, optional): _description_. Defaults to 5.\n",
    "        \"\"\"        \n",
    "        for i in range(n):\n",
    "            text_x1 = self.text_from_latent_code(latent_z, perturb)\n",
    "            print(f'Decoding {i+1}: {text_x1}')\n",
    "\n",
    "    def extract_last_token(hidden_states_tuple: Tuple[torch.Tensor], stack=False) -> Union[torch.Tensor, Tuple[torch.Tensor]]:\n",
    "        \"\"\"also turns on grad\n",
    "\n",
    "        Args:\n",
    "            hidden_states_tuple (Tuple[torch.Tensor]): _description_\n",
    "            stack (bool, optional): _description_. Defaults to False.\n",
    "\n",
    "        Returns:\n",
    "            Union[torch.Tensor, Tuple[torch.Tensor]]: _description_\n",
    "        \"\"\"             \n",
    "        # old_shape = hidden_states_tuple[0].shape\n",
    "        # new_shape = (old_shape[0], 1, old_shape[2])\n",
    "        # print(f'old shape: {old_shape}, new shape: {new_shape}')\n",
    "        hidden_states_list = []\n",
    "        for i in range(len(hidden_states_tuple)):\n",
    "            last_token_only = hidden_states_tuple[i][:, -1, :].requires_grad_(True) # for some reason this loses a dimension, also not sure if I need to clone\n",
    "            last_token_only = last_token_only.unsqueeze(1) # may not work if batch size is not 1?\n",
    "            hidden_states_list.append(last_token_only)\n",
    "            # assert last_token_only.shape == new_shape, f'Expected shape {new_shape}, got {last_token_only.shape}'\n",
    "        if stack:\n",
    "            shape = hidden_states_tuple[0].shape\n",
    "\n",
    "            stacked = torch.stack(hidden_states_tuple)\n",
    "            assert stacked[0].shape == shape\n",
    "            return stacked\n",
    "        else:\n",
    "            return tuple(hidden_states_list)\n",
    "\n",
    "    def hidden_from_latent_with_grad(self, latent_z: torch.Tensor,)-> Dict[str, Any]:\n",
    "        \"\"\"Just calls text_from_latent_code with use_grad=True and returns hidden states\n",
    "        Convenience method for backprop\n",
    "        Use greedy sampling for differentiability\n",
    "\n",
    "        Args:\n",
    "            latent_z (torch.Tensor): _description_\n",
    "\n",
    "        Returns:\n",
    "            Tuple[str, Tuple[torch.Tensor, ...]]: _description_\n",
    "        \"\"\"        \n",
    "        return self.text_from_latent_code(latent_z, return_dict=True, greedy=True, use_grad=True)\n",
    "\n",
    "    def text_from_latent_code(self, latent_z: torch.Tensor, perturb=0.0, return_hidden=False, greedy=False, use_grad=False, return_dict=False) -> str:\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            latent_z (torch.Tensor): shape (1, latent_size)\n",
    "            perturb (float, optional): _description_. Defaults to 0.0.\n",
    "\n",
    "        Returns:\n",
    "            str\n",
    "        \"\"\"    \n",
    "        if return_dict:\n",
    "            return_hidden = True    \n",
    "\n",
    "        past = latent_z + torch.randn_like(latent_z) * perturb * torch.norm(latent_z)\n",
    "        BOS_token = self.tokenizer_decoder.encode('<BOS>')\n",
    "\n",
    "        length = 150 # maximum length\n",
    "        out = Optimus.sample_sequence_conditional(\n",
    "            model=self.model_vae.decoder,\n",
    "            context=BOS_token,\n",
    "            past=past,\n",
    "            length= length, # Chunyuan: Fix length; or use <EOS> to complete a sentence\n",
    "            temperature=self.args.temperature,\n",
    "            top_k=self.args.top_k,\n",
    "            top_p=self.args.top_p,\n",
    "            device=self.args.device,\n",
    "            decoder_tokenizer = self.tokenizer_decoder,\n",
    "            return_hidden = return_hidden,\n",
    "            greedy=greedy,\n",
    "            use_grad=use_grad,\n",
    "        )\n",
    "        if return_hidden:\n",
    "            out, hidden = out\n",
    "            for tensor in hidden:\n",
    "                tensor.requires_grad_(True)\n",
    "        tokens = out[0,:].tolist()\n",
    "        text_x1 = self.tokenizer_decoder.decode(tokens, clean_up_tokenization_spaces=True)\n",
    "        text_x1 = text_x1.split()[1:-1]\n",
    "        text_x1 = ' '.join(text_x1)\n",
    "        \n",
    "        if return_dict:\n",
    "            res = {'hidden': hidden, 'text': text_x1, 'num_tokens': len(tokens)}\n",
    "            return res\n",
    "        elif return_hidden:\n",
    "            return text_x1, hidden, len(tokens)\n",
    "        else:\n",
    "            return text_x1\n",
    "    \n",
    "    def get_token_ids(self, text: str) -> List[int]:\n",
    "        \"\"\"also prepends BOS token\n",
    "\n",
    "        Args:\n",
    "            text (str): _description_\n",
    "\n",
    "        Returns:\n",
    "            List[int]: _description_\n",
    "        \"\"\"        \n",
    "        token_ids = self.model_vae.tokenizer_decoder.encode('<BOS>' + text)\n",
    "        token_ids = torch.tensor(token_ids, dtype=torch.long, device=self.device)\n",
    "        return token_ids.unsqueeze(0)\n",
    "\n",
    "    def text_to_latent_to_text_activations(self, text: str, averaging_num=1, greedy=True) -> torch.Tensor:\n",
    "        \"\"\"given text, encode into latent, then generate averaging_num times with latent and BOS, and return averaged activations\n",
    "\n",
    "        Args:\n",
    "            text (str): _description_\n",
    "            averaging_num (int, optional): number of times to generate text and average hidden state. Defaults to 1.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: last token activations of shape (self.num_layers + 1, 1, 1, self.latent_size)\n",
    "        \"\"\"       \n",
    "        latent_z = self.latent_code_from_text(text)[0]\n",
    "        # inputs = {'input_ids': self.bos_id, 'past': latent_z}\n",
    "        # if greedy:\n",
    "        #     raise NotImplementedError\n",
    "\n",
    "        #2. Put latent through vae decoder and Get hidden state \n",
    "        for i in range(averaging_num):\n",
    "            out = self.hidden_from_latent_with_grad(latent_z)\n",
    "            text, hidden_states_unformatted = out['text'], out['hidden']\n",
    "            hidden_states_last_token = Optimus.extract_last_token(hidden_states_unformatted)\n",
    "            hidden_states_last_token = torch.stack(hidden_states_last_token)\n",
    "            # hidden_states_all_tokens = torch.stack(hidden_states_unformatted) # hidden_states reformated from list of tensors to single tensor\n",
    "            # hidden_states_last_token = hidden_states_all_tokens[..., -1, :]\n",
    "            if i == 0:\n",
    "                hidden_states_last_token_averaged = hidden_states_last_token.clone().to(self.device)\n",
    "            else:\n",
    "                hidden_states_last_token_averaged += hidden_states_last_token\n",
    "        hidden_states_last_token_averaged /= averaging_num\n",
    "        if hidden_states_last_token_averaged.shape != (self.num_layers + 1, 1, 1, self.hidden_size):\n",
    "            # print(hidden_states_last_token_averaged.shape)\n",
    "            raise ValueError('hidden_states_last_token_averaged has wrong shape')\n",
    "        return text, hidden_states_last_token_averaged\n",
    "        \n",
    "        # hidden_states = self.model_decoder_with_hidden(**inputs)[2] # copied from Optimus.sample_sequence_conditional, don't know why this works\n",
    "        # current_direction = torch.stack(hidden_states).view(-1) # this may stack from multiple sequence inputs, check\n",
    "\n",
    "\n",
    "    def sample_sequence_conditional(\n",
    "            model, length, context, past=None, num_samples=1, temperature=1, top_k=0, top_p=0.0, device='cpu', decoder_tokenizer=None, return_hidden=False,\n",
    "            greedy=False, use_grad=False\n",
    "            ):\n",
    "        context = torch.tensor(context, dtype=torch.long, device=device)\n",
    "        context = context.unsqueeze(0).repeat(num_samples, 1)\n",
    "        generated = context\n",
    "        eos = False\n",
    "        if not use_grad:\n",
    "            context = torch.no_grad()\n",
    "        else:\n",
    "            context = torch.enable_grad()  # This is a no-op context manager\n",
    "\n",
    "        with context:\n",
    "            # while True:\n",
    "            for _ in range(length):\n",
    "                inputs = {'input_ids': generated, 'past': past}\n",
    "                outputs = model(**inputs)  # Note: we could also use 'past' with GPT-2/Transfo-XL/XLNet (cached hidden-states)\n",
    "                next_token_logits = outputs[0][0, -1, :] / temperature\n",
    "                if greedy:\n",
    "                    # assert next_token_logits.shape == (50257,)\n",
    "                    next_token = torch.argmax(next_token_logits, dim=-1).unsqueeze(0)\n",
    "                    # generated = torch.cat((generated, next_token.unsqueeze(0)), dim=1)\n",
    "                else:\n",
    "                    filtered_logits = Optimus.top_k_top_p_filtering(next_token_logits, top_k=top_k, top_p=top_p)\n",
    "                    next_token = torch.multinomial(F.softmax(filtered_logits, dim=-1), num_samples=1)\n",
    "                generated = torch.cat((generated, next_token.unsqueeze(0)), dim=1)\n",
    "\n",
    "                # pdb.set_trace()\n",
    "                if next_token.unsqueeze(0)[0,0].item() == decoder_tokenizer.encode('<EOS>')[0]:\n",
    "                    eos = True\n",
    "                    break\n",
    "        if not eos:\n",
    "            print('Reached maximum length without <EOS> token')\n",
    "        if return_hidden:\n",
    "            return generated, outputs[2] # return hidden state as of generating last token\n",
    "        else:\n",
    "            return generated\n",
    "    \n",
    "    def top_k_top_p_filtering(logits, top_k=0, top_p=0.0, filter_value=-float('Inf')):\n",
    "        \"\"\" Filter a distribution of logits using top-k and/or nucleus (top-p) filtering\n",
    "            Args:\n",
    "                logits: logits distribution shape (vocabulary size)\n",
    "                top_k > 0: keep only top k tokens with highest probability (top-k filtering).\n",
    "                top_p > 0.0: keep the top tokens with cumulative probability >= top_p (nucleus filtering).\n",
    "                    Nucleus filtering is described in Holtzman et al. (http://arxiv.org/abs/1904.09751)\n",
    "            From: https://gist.github.com/thomwolf/1a5a29f6962089e871b94cbd09daf317\n",
    "        \"\"\"\n",
    "        assert logits.dim() == 1  # batch size 1 for now - could be updated for more but the code would be less clear\n",
    "        top_k = min(top_k, logits.size(-1))  # Safety check\n",
    "        if top_k > 0:\n",
    "            # Remove all tokens with a probability less than the last token of the top-k\n",
    "            indices_to_remove = logits < torch.topk(logits, top_k)[0][..., -1, None]\n",
    "            logits[indices_to_remove] = filter_value\n",
    "\n",
    "        if top_p > 0.0:\n",
    "            sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n",
    "            cumulative_probs = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n",
    "\n",
    "            # Remove tokens with cumulative probability above the threshold\n",
    "            sorted_indices_to_remove = cumulative_probs > top_p\n",
    "            # Shift the indices to the right to keep also the first token above the threshold\n",
    "            sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n",
    "            sorted_indices_to_remove[..., 0] = 0\n",
    "\n",
    "            indices_to_remove = sorted_indices[sorted_indices_to_remove]\n",
    "            logits[indices_to_remove] = filter_value\n",
    "        return logits\n",
    "    \n",
    "    def is_latent(self, x):\n",
    "        return isinstance(x, torch.Tensor) and x.shape == (1, self.args.latent_size)\n",
    "    \n",
    "    def print_text(self, *args, n=5, perturb=0.0):\n",
    "        for arg in args:\n",
    "            if isinstance(arg, str):\n",
    "                print(f'\"{arg}\" encoded and decoded:')\n",
    "                latent = self.latent_code_from_text(arg)[0]\n",
    "            elif self.is_latent(arg):\n",
    "                latent = arg\n",
    "            else:\n",
    "                raise ValueError('Input must be string or latent')\n",
    "            self.print_n_texts_from_latent_code(latent, n, perturb)\n",
    "            print('\\n')\n",
    "    \n",
    "    def interpolate(self, num_interpolation_steps):   \n",
    "        latent_z1, coded_length1 = self.latent_code_from_text()\n",
    "        latent_z2, coded_length2 = self.latent_code_from_text(self.args.sent_target, self.tokenizer_encoder, self.model_vae, self.args)\n",
    "\n",
    "        result = defaultdict(str)\n",
    "\n",
    "        num_steps = num_interpolation_steps + 1\n",
    "        for step in range(num_steps+1):\n",
    "            latent_z = latent_z1 + (latent_z2 - latent_z1) * step * 1.0/num_steps\n",
    "            \n",
    "            text_interpolate = self.text_from_latent_code(latent_z, self.model_vae, self.args, self.tokenizer_decoder)\n",
    "            result[step] = text_interpolate\n",
    "            print(text_interpolate)\n",
    "\n",
    "        return result\n",
    "    \n",
    "    def print_greedy(self, latent):\n",
    "        text = self.text_from_latent_code(latent, greedy=True)\n",
    "        print(text)\n",
    "\n",
    "\n",
    "class Args:\n",
    "    #     parser = argparse.ArgumentParser()\n",
    "    def __init__(self, train_data_file, eval_data_file, checkpoint_dir, output_dir, checkpoint_number=508523):\n",
    "        #     parser.add_argument(\"--train_data_file\", default=None, type=str, required=True,\n",
    "        #                         help=\"The input training data file (a text file).\")\n",
    "        self.train_data_file = train_data_file\n",
    "        #     parser.add_argument(\"--eval_data_file\", default=None, type=str,\n",
    "        #                         help=\"An input evaluation data file to evaluate the perplexity on (a text file).\")\n",
    "        self.eval_data_file = eval_data_file\n",
    "        #     parser.add_argument(\"--checkpoint_dir\", default=None, type=str, required=True,\n",
    "        #                         help=\"The directory where checkpoints are saved.\")\n",
    "        self.checkpoint_dir = checkpoint_dir\n",
    "        #     parser.add_argument(\"--output_dir\", default=None, type=str, required=True,\n",
    "        #                         help=\"The output directory where the model predictions and checkpoints will be written.\")\n",
    "        self.output_dir = output_dir\n",
    "        #     parser.add_argument(\"--dataset\", default='Snli', type=str, help=\"The dataset.\")\n",
    "        self.dataset = 'Snli' # may have to change to wiki?\n",
    "\n",
    "        #     ## Variational auto-encoder\n",
    "        #     parser.add_argument(\"--latent_size\", default=32, type=int, help=\"Latent space dimension.\")\n",
    "        self.latent_size = 768\n",
    "        #     parser.add_argument(\"--total_sents\", default=10, type=int, help=\"Total sentences to test recontruction.\")\n",
    "        self.total_sents = 10\n",
    "        #     parser.add_argument(\"--num_interpolation_steps\", default=10, type=int, help=\"Total sentences to test recontruction.\")\n",
    "        self.num_interpolation_steps = 10\n",
    "        #     parser.add_argument(\"--play_mode\", default=\"interpolation\", type=str,\n",
    "        #                         help=\"interpolation or reconstruction.\")\n",
    "        self.play_mode = \"interpolation\"\n",
    "\n",
    "\n",
    "        #     ## Encoder options\n",
    "        #     parser.add_argument(\"--encoder_model_type\", default=\"bert\", type=str,\n",
    "        #                         help=\"The encoder model architecture to be fine-tuned.\")\n",
    "        self.encoder_model_type = \"bert\"\n",
    "        #     parser.add_argument(\"--encoder_model_name_or_path\", default=\"bert-base-cased\", type=str,\n",
    "        #                         help=\"The encoder model checkpoint for weights initialization.\")\n",
    "        self.encoder_model_name_or_path = \"bert-base-cased\"\n",
    "        #     parser.add_argument(\"--encoder_config_name\", default=\"\", type=str,\n",
    "        #                         help=\"Optional pretrained config name or path if not the same as model_name_or_path\")\n",
    "        self.encoder_config_name = \"\"\n",
    "        #     parser.add_argument(\"--encoder_tokenizer_name\", default=\"\", type=str,\n",
    "        #                         help=\"Optional pretrained tokenizer name or path if not the same as model_name_or_path\")\n",
    "        self.encoder_tokenizer_name = \"\"\n",
    "\n",
    "            ## Decoder options\n",
    "        #     parser.add_argument(\"--decoder_model_type\", default=\"gpt2\", type=str,\n",
    "        #                         help=\"The decoder model architecture to be fine-tuned.\")\n",
    "        self.decoder_model_type = \"gpt2\"\n",
    "        #     parser.add_argument(\"--decoder_model_name_or_path\", default=\"bert-base-cased\", type=str,\n",
    "        #                         help=\"The decoder model checkpoint for weights initialization.\")\n",
    "        self.decoder_model_name_or_path = \"bert-base-cased\"\n",
    "        #     parser.add_argument(\"--decoder_config_name\", default=\"\", type=str,\n",
    "        #                         help=\"Optional pretrained config name or path if not the same as model_name_or_path\")\n",
    "        self.decoder_config_name = \"\"\n",
    "        #     parser.add_argument(\"--decoder_tokenizer_name\", default=\"\", type=str,\n",
    "        #                         help=\"Optional pretrained tokenizer name or path if not the same as model_name_or_path\")\n",
    "        self.decoder_tokenizer_name = \"\"\n",
    "\n",
    "        #     parser.add_argument(\"--per_gpu_train_batch_size\", default=1, type=int,\n",
    "        #                         help=\"Batch size per GPU/CPU for training.\")\n",
    "        self.per_gpu_train_batch_size = 1\n",
    "        #     parser.add_argument(\"--per_gpu_eval_batch_size\", default=1, type=int,\n",
    "        #                         help=\"Batch size per GPU/CPU for evaluation.\")\n",
    "        self.per_gpu_eval_batch_size = 1\n",
    "        #     parser.add_argument('--gloabl_step_eval', type=int, default=661,\n",
    "        #                         help=\"Evaluate the results at the given global step\")\n",
    "        self.gloabl_step_eval = checkpoint_number\n",
    "        #     parser.add_argument(\"--max_seq_length\", default=512, type=int,\n",
    "        #                         help=\"Optional input sequence length before tokenization. The sequence will be dropped if it is longer the max_seq_length\")\n",
    "        self.max_seq_length = 512\n",
    "        #     # Interact with users\n",
    "        #     parser.add_argument(\"--interact_with_user_input\", action='store_true', help=\"Use user input to interact_with.\")\n",
    "        self.interact_with_user_input = False\n",
    "        #     parser.add_argument(\"--sent_source\", type=str, default=\"\")\n",
    "        self.sent_source = \"\"\n",
    "        #     parser.add_argument(\"--sent_target\", type=str, default=\"\")\n",
    "        self.sent_target = \"\"\n",
    "        #     parser.add_argument(\"--sent_input\", type=str, default=\"\")\n",
    "        self.sent_input = \"\"\n",
    "        #     parser.add_argument(\"--degree_to_target\", type=float, default=\"1.0\")\n",
    "        self.degree_to_target = 1.0\n",
    "\n",
    "        #     ## Variational auto-encoder\n",
    "        #     parser.add_argument(\"--nz\", default=32, type=int,\n",
    "        #                         help=\"Latent space dimension.\")\n",
    "        self.nz = 32\n",
    "\n",
    "        #     parser.add_argument(\"--prompt\", type=str, default=\"\")\n",
    "        self.prompt = \"\"\n",
    "        #     parser.add_argument(\"--padding_text\", type=str, default=\"\")\n",
    "        self.padding_text = \"\"\n",
    "        #     parser.add_argument(\"--length\", type=int, default=20)\n",
    "        self.length = 20\n",
    "        #     parser.add_argument(\"--temperature\", type=float, default=1.0)\n",
    "        self.temperature = 1.0\n",
    "        #     parser.add_argument(\"--top_k\", type=int, default=0)\n",
    "        self.top_k = 0\n",
    "        #     parser.add_argument(\"--top_p\", type=float, default=1.0)\n",
    "        self.top_p = 1.0\n",
    "        #     parser.add_argument(\"--no_cuda\", action='store_true',\n",
    "        #                         help=\"Avoid using CUDA when available\")\n",
    "        self.no_cuda = False\n",
    "        #     parser.add_argument('--seed', type=int, default=42,\n",
    "        #                         help=\"random seed for initialization\")\n",
    "        self.seed = 42\n",
    "\n",
    "        #     parser.add_argument(\"--block_size\", default=-1, type=int,\n",
    "        #                         help=\"Optional input sequence length after tokenization.\"\n",
    "        #                              \"The training dataset will be truncated in block of this size for training.\"\n",
    "        #                              \"Default to the model max input length for single sentence inputs (take into account special tokens).\")\n",
    "        self.block_size = -1\n",
    "        #     parser.add_argument(\"--do_lower_case\", action='store_true',\n",
    "        #                         help=\"Set this flag if you are using an uncased model.\")\n",
    "        self.do_lower_case = False\n",
    "\n",
    "        #     parser.add_argument(\"--use_philly\", action='store_true',\n",
    "        #                         help=\"Use Philly for computing.\")\n",
    "        self.use_philly = False\n",
    "\n",
    "        #     args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instantiate Optimus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have added 3 tokens to GPT2\n"
     ]
    }
   ],
   "source": [
    "#TODO decouple from Optimus\n",
    "vae32 = Optimus(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Optimus with latent_size 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Optimus with latent_size 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vae768 = Optimus(768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# good_review = \"\"\"\n",
    "# \"The Radiant Dream\" is a visually stunning and thought-provoking film that immerses viewers in a mesmerizing world \n",
    "# of imagination and wonder. The cinematography is breathtaking, with each frame meticulously crafted to evoke a sense\n",
    "#  of awe and beauty. The performances are outstanding, bringing depth and authenticity to the characters. \n",
    "#  The storyline is captivating, exploring profound themes and leaving audiences with a sense of reflection and inspiration.\n",
    "# \"\"\"\n",
    "# bad_review = \"\"\"\n",
    "# \"Lost in Shadows\" is a disappointing film that fails to live up to its potential. \n",
    "# Despite promising visuals, the narrative lacks coherence and fails to engage the audience. \n",
    "# The characters are underdeveloped, making it difficult to form a connection or invest in their journey. \n",
    "# The pacing is uneven, with slow moments that drag the story down and prevent it from building momentum. \n",
    "# Overall, \"Lost in Shadows\" falls short in delivering a satisfying cinematic experience.\n",
    "# \"\"\"\n",
    "# good_review_latent_decoded, good_review_activations = vae32.text_to_latent_to_text_activations(good_review, greedy=True)\n",
    "# print(good_review_latent_decoded)\n",
    "\n",
    "# bad_review_latent_decoded, bad_review_activations = vae32.text_to_latent_to_text_activations(bad_review, greedy=True)\n",
    "# print(bad_review_latent_decoded)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare effect of latent size\n",
    "\n",
    "Seems like latent_size=32 makes the sentences \"closer\"? But reconstruction seems worse\n",
    "\n",
    "Observations:\n",
    "- Some latents get \"translated\" into either nothing or seemingly meaningless rambling. Some latents produce semantically similar words though.\n",
    "- Longer sentences seem to reconstruct better than words/short sentences?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hidden = vae32.get_activations(vae32.latent_code_from_text('hello')[0], 'hello')\n",
    "# print (hidden.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vae32.print_text(\n",
    "#     \"love\", \n",
    "#     'hate', \n",
    "#     'I love you so much!', \n",
    "#     'I hate you so much!'\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vae768.print_text(\n",
    "#     \"love\", \n",
    "#     'hate', \n",
    "#     'I love you so much!', \n",
    "#     'I hate you so much!'\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vae32.print_text(shaq, benzene)\n",
    "# baseline_sports = \"basketball \" * 20\n",
    "# baseline_chemistry = \"chemistry \" * 20\n",
    "# vae32.print_text(baseline_sports, baseline_chemistry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vae768.print_text(shaq, benzene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vae32.print_text(shaq, benzene, perturb=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vae768.print_text(shaq, benzene, perturb=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test optimus\n",
    "# text_love = \"I love you so much!\"\n",
    "# latent_love = vae32.latent_code_from_text(text_love)[0]\n",
    "# # text_hate = \"I hate you so much!\"\n",
    "# # latent_hate = vae32.latent_code_from_text(text_hate)[0]\n",
    "# print(latent_love.shape)\n",
    "# # print(len(text_original))\n",
    "# vae32.print_n_texts_from_latent_code(latent_love, 10)\n",
    "# vae32.print_n_texts_from_latent_code(latent_hate, 10)\n",
    "# vae32.print_n_texts_from_latent_code(latent_love - latent_hate, 10)\n",
    "# vae32.print_n_texts_from_latent_code(-latent_love + latent_hate, 10)\n",
    "# for i in range(10):\n",
    "#     print(vae.text_from_latent_code(latent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Visualization Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7fcd56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "def cosim(a, b):\n",
    "    return nn.functional.cosine_similarity(a, b, dim=0).item()\n",
    "\n",
    "# class TextTrainer(LatentTrainer):\n",
    "#     def __init__(\n",
    "#         self, optimus: Optimus, target_text, training_args, latent_module, logging_steps=1e2,\n",
    "#     ):\n",
    "\n",
    "# class ActivationTrainer(LatentTrainer):\n",
    "#     def __init__(\n",
    "#         self, optimus: Optimus, target_dir, training_args, latent_module, logging_steps=1e2,\n",
    "#         ):\n",
    "        \n",
    "\n",
    "class LatentTrainer(Trainer):\n",
    "    def __init__(\n",
    "        self, optimus: Optimus, training_args, latent_module, logging_steps=1e2,\n",
    "        target_text=None,\n",
    "        target_dir=None,\n",
    "        length_reg=0.0,\n",
    "    ):\n",
    "        \"\"\"_summary_\n",
    "        Example use case: target_dir is hidden of last token of shaq\n",
    "        loss is 1 - cosine_similarity(hidden - target)\n",
    "        Loss transposed to be min at 0, max at 2\n",
    "\n",
    "        Args:\n",
    "            optimus (Optimus): _description_\n",
    "            target_dir (_type_): _description_\n",
    "            training_args (_type_): _description_\n",
    "            latent (_type_): _description_\n",
    "        \"\"\"        \n",
    "        '''\n",
    "        decoder: decoder model from an Optimus VAE, must have output_hidden_states=True\n",
    "        target_dir: of size (1 + num_layers, 1, 1, latent_size)\n",
    "        '''\n",
    "        self.targeting_text = target_text != None\n",
    "        self.targeting_dir = target_dir != None\n",
    "\n",
    "        if self.targeting_text and self.targeting_dir:\n",
    "            raise ValueError('Can only target text or activation direction, not both')\n",
    "\n",
    "        self.target_text = target_text\n",
    "        self.target_dir = target_dir\n",
    "\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        latent_module.to(self.device)\n",
    "        super().__init__(model=latent_module, args=training_args)\n",
    "        self.optimus = optimus # make sure this outputs hidden\n",
    "        if self.targeting_dir:\n",
    "            self.target_dir = target_dir.to(self.device).view(-1) #flattened\n",
    "        # assert target_dir.shape == \n",
    "        context = optimus.model_vae.tokenizer_decoder.encode('<BOS>')\n",
    "        context = torch.tensor(context, dtype=torch.long, device=self.device)\n",
    "        self.context = context.unsqueeze(0).repeat(1, 1)  \n",
    "        self.loss_values = []\n",
    "        self.logging_steps = logging_steps\n",
    "        self.length_reg = length_reg\n",
    "\n",
    "    def compute_loss(self, latent_module, return_cosim=False,\n",
    "                     #TODO maybe change cosim to compute layerwise so we know where the cosim loss is coming from\n",
    "        # return_dir=False,\n",
    "        ): \n",
    "        '''\n",
    "        latent is a trainable parameter/model with shape [1, latent_size]\n",
    "        '''\n",
    "        #1. Extract params from latent model\n",
    "        latent = latent_module.get_parameter('latent').clone().requires_grad_(True)\n",
    "        # inputs = {'input_ids': self.context, 'past': past}\n",
    "        \n",
    "        #2. Put latent through vae decoder and Get hidden state\n",
    "        # hidden_states = self.decoder(**inputs)[2] \n",
    "        \n",
    "        if self.targeting_dir:\n",
    "            out = self.optimus.hidden_from_latent_with_grad(latent,) #generates until EOS and returns hidden state\n",
    "            text, hidden_states_tuple, output_length = out['text'], out['hidden'], out['num_tokens']\n",
    "            \n",
    "            hidden_states_last_token = Optimus.extract_last_token(hidden_states_tuple)\n",
    "            hidden_states_last_token = torch.stack(hidden_states_last_token) # hidden_states reformated from tuple of tensors to single tensor\n",
    "            # print(f'hidden_states_last_token shape: {hidden_states_last_token.shape}')\n",
    "            # hidden_states_last_token = hidden_states_all_tokens[..., -1, :]\n",
    "            current_dir = hidden_states_last_token.view(-1) #flatten hidden layers into 1d vector\n",
    "            if current_dir.shape != self.target_dir.shape:\n",
    "                print(f'Target shape is {self.target_dir.shape} but current_dir shape is {current_dir.shape}')\n",
    "                raise ValueError\n",
    "            #3. Compute loss with cosine similarity between hidden states\n",
    "            similarity = cosim(current_dir, self.target_dir) \n",
    "            loss = 1 - similarity + self.length_reg * output_length ** 2\n",
    "            assert loss.numel() == 1, \"Loss must be a scalar\"\n",
    "            # assert loss <= 2 and loss >= 0\n",
    "            \n",
    "            return (loss, similarity) if return_cosim else loss\n",
    "        elif self.targeting_text:\n",
    "            raise NotImplementedError\n",
    "        else:\n",
    "            raise ValueError('Must target text or activation direction')\n",
    "    \n",
    "    \n",
    "\n",
    "    def train(self):\n",
    "\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=self.args.learning_rate)\n",
    "        num_epochs = int(self.args.num_train_epochs)\n",
    "        latent_module = self.model\n",
    "        for epoch in range(num_epochs):\n",
    "            # for step, batch in enumerate(self.get_train_dataloader()):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            loss = self.compute_loss(latent_module)\n",
    "            loss.backward(\n",
    "                retain_graph=True\n",
    "                )\n",
    "            \n",
    "            latent = latent_module.get_parameter('latent')\n",
    "            if torch.all(latent.grad == 0):\n",
    "                print('Latent grad is 0')\n",
    "\n",
    "            # for name, param in self.model.named_parameters():\n",
    "            #     print(f'Before step: {name}, {param.data}')\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            # After optimizer.step()\n",
    "            # for name, param in self.model.named_parameters():\n",
    "            #     print(f'After step: {name}, {param.data}')\n",
    "            loss_scalar = loss.item()\n",
    "            self.loss_values.append(loss_scalar)\n",
    "            #TODO save logs somewhere\n",
    "            if epoch % self.logging_steps == 0:\n",
    "                print(f\"Epoch {epoch}\")\n",
    "                self.optimus.print_greedy(latent)\n",
    "                print(f'Loss = 1 - cosine_similarity = {loss_scalar}')\n",
    "                # print(text)\n",
    "            # print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
    "        plt.plot(self.loss_values)\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss = 1 - Cosine_Similarity(hidden_state, target_direction)')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b75206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cosim distribution of random latents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize trainer and run loop\n",
    "\n",
    "# dummy_data = {'dummy':'dummy',} # may be needed to appease Trainer\n",
    "# dummy_data = Dataset.from_dict(dummy_data)\n",
    "\n",
    "NUM_LAYERS = 12\n",
    "BATCH_SIZE = 1\n",
    "SEQ_LEN = 1\n",
    "HIDDEN_SIZE = 768\n",
    "\n",
    "def train(\n",
    "    optimus: Optimus, target_dir=None, lr=1e-4, num_epochs=1e3, logging_steps=100, init_norm=1.0, init_latent=None, \n",
    "        length_reg = 0.0 #1e-2,\n",
    "        save_name='test',\n",
    "        num_trainings=1,\n",
    "        ):\n",
    "    for i in range(num_trainings):\n",
    "        latent_size = optimus.latent_size\n",
    "        training_args = TrainingArguments(output_dir=\"test_trainer\")\n",
    "        training_args.num_train_epochs = num_epochs\n",
    "        training_args.learning_rate = lr\n",
    "\n",
    "        target_dir_shape = (NUM_LAYERS + 1, BATCH_SIZE, SEQ_LEN, HIDDEN_SIZE)\n",
    "        # decoder = vae.model_decoder_with_hidden.to(device)\n",
    "        if target_dir is None:\n",
    "            target_dir = torch.randn(target_dir_shape).to(device) \n",
    "        else:\n",
    "            assert target_dir.shape == target_dir_shape, \"target_dir must have shape (NUM_LAYERS + 1, BATCH_SIZE, SEQ_LEN, HIDDEN_SIZE)\"\n",
    "        \n",
    "        latent_module = nn.Module()\n",
    "        if init_latent == None:\n",
    "            param = torch.randn(1, latent_size)\n",
    "            param /= param.norm() * init_norm\n",
    "        else:\n",
    "            assert init_latent.shape == (1, latent_size)\n",
    "            param = init_latent\n",
    "        param = nn.Parameter(data=param, requires_grad=True)\n",
    "        # param_init = param.clone().detach().to(device)\n",
    "        latent_module.register_parameter(\"latent\", param)\n",
    "        latent_module.to(device)\n",
    "        # original_latent = param.clone().detach().to(device)\n",
    "\n",
    "        trainer = LatentTrainer(\n",
    "            optimus, training_args, latent_module, logging_steps=logging_steps,\n",
    "            target_dir=target_dir,\n",
    "            length_reg=length_reg,\n",
    "            # train_dataset=dummy_data,\n",
    "            )\n",
    "        trainer.train()\n",
    "        #TODO figure out file structure\n",
    "        torch.save(latent_module.state_dict(), f'{save_name}-{}.pth')\n",
    "    # optimus.print_greedy(latent.get_parameter('latent'))\n",
    "    # latent_diff = (param - param_init).view(-1).norm()\n",
    "    # print(latent_diff)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# activations = vae32.text_from_latent_code(torch.randn(1, 32).to(device), return_hidden=True)[1]\n",
    "# stacked = torch.stack(activations)\n",
    "# print(stacked.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D'Angelo is a former professional boxer, who has won five world titles, including the WBA Light Middleweight Title, the WBA Light Middleweight Title, the WBA Light Middleweight Title, the WBA Light Middleweight Title, and the WBA Light Middleweight Title.\n",
      "2.6317951679229736\n"
     ]
    }
   ],
   "source": [
    "# shaq_activations = vae32.text_to_latent_to_activations(shaq, averaging_num=1)\n",
    "#TODO maybe try training with regularization against length of output\n",
    "shaq_latent_decoded, shaq_activations = vae32.text_to_latent_to_text_activations(shaq, greedy=True)\n",
    "print(shaq_latent_decoded)\n",
    "shaq_latent_norm = vae32.latent_code_from_text(shaq,)[0].norm().item()\n",
    "print(shaq_latent_norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is a synthetic compound of the ethyl alcohols, ethyl alcohols, and ethyl alcohols, which are used in the manufacture of alcohols, and is used in the manufacture of alcohols, and in the manufacture of alcohols, and in the manufacture of alcohols.\n",
      "2.8745837211608887\n"
     ]
    }
   ],
   "source": [
    "benzene_latent_decoded, benzene_activations = vae32.text_to_latent_to_text_activations(benzene, greedy=True)\n",
    "print(benzene_latent_decoded)\n",
    "benzene_latent = vae32.latent_code_from_text(benzene,)[0]\n",
    "benzene_latent_norm = benzene_latent.norm().item()\n",
    "print(benzene_latent_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9eefa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_size = 32\n",
    "target_hidden = shaq_activations\n",
    "similarity_list = []\n",
    "for i in range(10):\n",
    "    latent = torch.randn(1, latent_size)\n",
    "    hidden_full_dict = vae32.hidden_from_latent_with_grad(latent) #returns dict\n",
    "    last_token_hidden = vae32.extract_last_token(hidden_full_dict, stack=True)\n",
    "    similarity = cosim(last_token_hidden.view(-1), target_hidden.view(-1))\n",
    "    similarity_list.append(similarity)\n",
    "print(similarity_list)\n",
    "#TODO plot difference, compare with distribution of training result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "The first of these was the \"Bergamasque\" (a term coined by the author of \"The New York Times\") and the second was the \"Bergamasque\" (a term coined by the author of \"The New York Times\").\n",
      "Loss = 1 - cosine_similarity = 0.09309267997741699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50\n",
      "The first of these was the \"Bergamasque\" (Bergamasque) in the 1990s, which was the first to be certified by the National Academy of Sciences.\n",
      "Loss = 1 - cosine_similarity = 0.07443404197692871\n",
      "Epoch 100\n",
      "The first of the three to be inducted into the Hall of Fame was the \"Dirty Dancing\" singer, who was inducted into the Hall of Fame in 1998.\n",
      "Loss = 1 - cosine_similarity = 0.05806189775466919\n",
      "Epoch 150\n",
      "The first of the three to be inducted into the Hall of Fame was the former New York City Firefighter, John C. C. C. C.\n",
      "Loss = 1 - cosine_similarity = 0.2690574526786804\n",
      "Epoch 200\n",
      "The first female player to play in the league was the former player, J.J.\n",
      "Loss = 1 - cosine_similarity = 0.31585001945495605\n",
      "Epoch 250\n",
      "The first female athlete to be inducted into the Hall of Fame was the former American Athletic Conference (AAC) player, J.J.\n",
      "Loss = 1 - cosine_similarity = 0.2870967984199524\n",
      "Epoch 300\n",
      "The first female athlete to be inducted into the Hall of Fame was the former University of Michigan football player, J.J.\n",
      "Loss = 1 - cosine_similarity = 0.09991776943206787\n",
      "Epoch 350\n",
      "The first female athlete to be named in the sport was the former American Olympic gold medalist, Mary Ann.\n",
      "Loss = 1 - cosine_similarity = 0.09948533773422241\n",
      "Epoch 400\n",
      "He is the only player to have played in the top ten in the \"Piano World\" category.\n",
      "Loss = 1 - cosine_similarity = 0.04508233070373535\n",
      "Epoch 450\n",
      "He is the only player to have played in the National Hockey League (NHL) since the 1980s.\n",
      "Loss = 1 - cosine_similarity = 0.0431172251701355\n",
      "Epoch 500\n",
      "He is the only player to have played in the National Hockey League (NHL) since the 1980s.\n",
      "Loss = 1 - cosine_similarity = 0.04076504707336426\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#TODO: maybe fix retain_graph if speed is a bottleneck\n",
    "train(vae32, target_dir=shaq_activations, lr=1e-3, num_epochs=501, logging_steps=50, \n",
    "      init_norm=shaq_latent_norm,\n",
    "      # init_latent=benzene_latent,\n",
    "      )\n",
    "# train(vae768, 768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccb0ebb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1d409d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like post training we go to one/zero word sentences (from a random init latent). Maybe will help if we init from an actual sentence\n",
    "\n",
    "Also may be a signal that the latent space is less 'dense' with meaningful sentences than we'd like. I thought using the latent=32 vae would help as sentences will be more 'densely packed' but empirically maybe this is evidence against that.\n",
    "\n",
    "May also need to regularize to penalize distance against actual meaningful sentences in the latent space?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from huggingface_hub import notebook_login\n",
    "\n",
    "# notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vae32.model_vae.push_to_hub(\"Optimus_VAE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) get a prompt with an question and answer where the answer is correct (e.g. Do dogs bark? Yes) and then also the same question with a wrong answer (e.g. Do dogs bark? No). \n",
    "\n",
    "(2) get the hidden states for each prompt at the last token position and subtract them. This gets you a 'truth vector' estimate. \n",
    "\n",
    "(3) Search in Optimus latent space for prompt that aligns with this direction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emotional = '''\n",
    "# Are you kidding me? LeBron James better than Michael Jordan? That's a laughable claim. \n",
    "# Six championships, ten scoring titles, unmatched defensive prowess, \n",
    "# and a killer instinct that LeBron can only dream of. \n",
    "# Jordan is the undisputed GOAT, and no amount of arguments will change that.\n",
    "# '''\n",
    "# emotional_latent_decoded, emotional_activations = vae32.text_to_latent_to_text_activations(emotional, greedy=True)\n",
    "# shaq_latent_decoded, shaq_activations = vae32.text_to_latent_to_text_activations(shaq, greedy=True)\n",
    "# print(emotional_latent_decoded)\n",
    "# print(shaq_latent_decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# male_text = \"male\" * 10\n",
    "# female_text = \"female\" * 10\n",
    "# male_tennis = \"\"\"\n",
    "# Rafael Nadal Parera (born 3 June 1986) is a Spanish professional tennis player. \n",
    "# Nadal has been ranked world No. 1 in singles by the Association of Tennis Professionals (ATP) for 209 weeks, \n",
    "# and has finished as the year-end No. 1 five times. \n",
    "# Nadal has won 22 Grand Slam men's singles titles, \n",
    "# including a record 14 French Open titles. \n",
    "# He has won 92 ATP singles titles, including 36 Masters titles, with 63 of these on clay courts. \n",
    "# Nadal is one of only two men to complete the Career Golden Slam in singles. \n",
    "# His 81 consecutive wins on clay constitute the longest single-surface win streak in the Open Era.\n",
    "# \"\"\"\n",
    "# female_tennis = \"\"\"\n",
    "# Serena Jameka Williams (born September 26, 1981) is an American former professional tennis player. \n",
    "# Widely regarded as one of the greatest tennis players of all time, \n",
    "# she was ranked world No. 1 in singles by the Women's Tennis Association (WTA) for 319 weeks, \n",
    "# including a joint-record 186 consecutive weeks, and finished as the year-end No. 1 five times. \n",
    "# She won 23 Grand Slam women's singles titles, the most in the Open Era, and the second-most of all time. \n",
    "# She is the only player to accomplish a career Golden Slam in both singles and doubles.\n",
    "# \"\"\"\n",
    "# male_latent_decoded, male_activations = vae32.text_to_latent_to_text_activations(male_tennis, greedy=True)\n",
    "# female_latent_decoded, female_activations = vae32.text_to_latent_to_text_activations(female_tennis, greedy=True)\n",
    "# print(male_latent_decoded)\n",
    "# print(female_latent_decoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dog_question = \"Do dogs bark? \"\n",
    "# dog_yes = dog_question + \"Yes.\" #\"Yes, dogs bark.\"\n",
    "# dog_no = dog_question + \"No.\" #\"No, dogs don't bark.\"\n",
    "\n",
    "# #TODO get a trainer that tries to find latent that generates to text\n",
    "# dog_yes_latent_decoded, dog_yes_activations = vae32.text_to_latent_to_text_activations(dog_yes, greedy=True)\n",
    "# print(dog_yes_latent_decoded)\n",
    "# # dog_yes_latent = vae32.latent_code_from_text(dog_yes,)[0]\n",
    "# # dog_yes_latent_norm = dog_yes_latent.norm().item()\n",
    "\n",
    "# dog_no_latent_decoded, dog_no_activations = vae32.text_to_latent_to_text_activations(dog_no, greedy=True)\n",
    "# print(dog_no_latent_decoded)\n",
    "# # dog_no_latent = vae32.latent_code_from_text(dog_no,)[0]\n",
    "# # dog_no_latent_norm = dog_no_latent.norm().item()\n",
    "\n",
    "# truth_direction = dog_yes_activations - dog_no_activations\n",
    "# truth_direction_norm = truth_direction.view(-1).norm().item()\n",
    "\n",
    "# train(vae32, target_dir=truth_direction, lr=1e-3, num_epochs=501, logging_steps=50, init_norm=truth_direction_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "display-redteam2",
   "language": "python",
   "name": "redteam2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
